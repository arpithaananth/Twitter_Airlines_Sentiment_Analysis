{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Through Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('Airline-Sentiment-2-w-AA.csv',encoding='latin-1')\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from autocorrect import Speller\n",
    "tweet_tok=  TweetTokenizer()\n",
    "spell=Speller(lang='en')\n",
    "stop_nltk= stopwords.words(\"english\")\n",
    "stop_updated= stop_nltk+['user']+['https://t.co.']+[' http://t.co/']+['...'] +['http co']\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens= tweet_tok.tokenize(text.lower())\n",
    "    stemmed=[lemm.lemmatize(term) for term in tokens if term not in  stop_updated and term not in list(punctuation) and len(term)>2]\n",
    "    stemmed_tok = [word for word in stemmed if word.isalpha()]\n",
    "    stemmed_tokens = [spell(word) for word in stemmed_tok]\n",
    "    res=' '.join(stemmed_tokens)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Clean_Tweets']= data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Clean_Tweets']=data['Clean_Tweets'].str.replace('#','')\n",
    "data['Clean_Tweets']=data['Clean_Tweets'].str.replace('@','')\n",
    "data['Clean_Tweets']=data['Clean_Tweets'].str.replace('http','')\n",
    "data['Clean_Tweets']=data['Clean_Tweets'].str.replace('co','')\n",
    "data['Clean_Tweets']=data['Clean_Tweets'].str.replace('_ùª _ùª ','')\n",
    "data['Clean_Tweets']=data['Clean_Tweets'].str.replace('â_ù â_ù','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "x1=LabelEncoder()  \n",
    "data['flagged_sentiment']= x1.fit_transform(data['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Google's Pretrained Model- word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_model= \"C:\\\\Users\\\\Arpitha Ananth\\\\Documents\\\\Programming in Data Science\\\\Text Processing\\\\word2vec\\\\GoogleNews-vectors-negative300.bin.gz\"\n",
    "embeddings= gensim.models.KeyedVectors.load_word2vec_format(google_model,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009094</td>\n",
       "      <td>-0.044189</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>0.061523</td>\n",
       "      <td>0.255859</td>\n",
       "      <td>-0.158203</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>-0.096680</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193359</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>-0.093262</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>-0.117676</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.180664</td>\n",
       "      <td>-0.086914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011475</td>\n",
       "      <td>-0.028662</td>\n",
       "      <td>-0.048035</td>\n",
       "      <td>0.028381</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.053278</td>\n",
       "      <td>-0.106189</td>\n",
       "      <td>0.100121</td>\n",
       "      <td>0.112695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073389</td>\n",
       "      <td>0.079224</td>\n",
       "      <td>-0.044080</td>\n",
       "      <td>0.040007</td>\n",
       "      <td>-0.046777</td>\n",
       "      <td>0.063672</td>\n",
       "      <td>0.102014</td>\n",
       "      <td>-0.096680</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>-0.038660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002590</td>\n",
       "      <td>0.048671</td>\n",
       "      <td>0.035540</td>\n",
       "      <td>0.034947</td>\n",
       "      <td>-0.072335</td>\n",
       "      <td>0.029393</td>\n",
       "      <td>0.051392</td>\n",
       "      <td>-0.091666</td>\n",
       "      <td>0.017008</td>\n",
       "      <td>0.080023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060529</td>\n",
       "      <td>0.023089</td>\n",
       "      <td>-0.013249</td>\n",
       "      <td>0.068396</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>-0.007010</td>\n",
       "      <td>-0.075910</td>\n",
       "      <td>0.066668</td>\n",
       "      <td>-0.069632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.097236</td>\n",
       "      <td>-0.018582</td>\n",
       "      <td>0.059896</td>\n",
       "      <td>-0.123081</td>\n",
       "      <td>0.062690</td>\n",
       "      <td>0.071913</td>\n",
       "      <td>-0.033997</td>\n",
       "      <td>0.069329</td>\n",
       "      <td>0.090702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>0.029351</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>-0.005778</td>\n",
       "      <td>-0.064236</td>\n",
       "      <td>0.040677</td>\n",
       "      <td>0.076152</td>\n",
       "      <td>0.029161</td>\n",
       "      <td>-0.007053</td>\n",
       "      <td>-0.011149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.110107</td>\n",
       "      <td>0.062714</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>-0.030945</td>\n",
       "      <td>-0.058258</td>\n",
       "      <td>0.097595</td>\n",
       "      <td>-0.039795</td>\n",
       "      <td>0.073257</td>\n",
       "      <td>0.130005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119110</td>\n",
       "      <td>0.138916</td>\n",
       "      <td>-0.155151</td>\n",
       "      <td>-0.036743</td>\n",
       "      <td>-0.139221</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>-0.003777</td>\n",
       "      <td>-0.038452</td>\n",
       "      <td>0.109802</td>\n",
       "      <td>-0.061951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.009094 -0.044189  0.099609 -0.076172 -0.056641  0.061523  0.255859   \n",
       "1  0.011475 -0.028662 -0.048035  0.028381  0.016113  0.005029  0.053278   \n",
       "2 -0.002590  0.048671  0.035540  0.034947 -0.072335  0.029393  0.051392   \n",
       "3  0.002969  0.097236 -0.018582  0.059896 -0.123081  0.062690  0.071913   \n",
       "4  0.110107  0.062714  0.003174  0.131836 -0.030945 -0.058258  0.097595   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.158203  0.016602 -0.096680  ... -0.193359  0.029907 -0.093262  0.053711   \n",
       "1 -0.106189  0.100121  0.112695  ... -0.073389  0.079224 -0.044080  0.040007   \n",
       "2 -0.091666  0.017008  0.080023  ... -0.060529  0.023089 -0.013249  0.068396   \n",
       "3 -0.033997  0.069329  0.090702  ... -0.004829  0.029351 -0.014119 -0.005778   \n",
       "4 -0.039795  0.073257  0.130005  ... -0.119110  0.138916 -0.155151 -0.036743   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.117676  0.069824  0.105957  0.144531  0.180664 -0.086914  \n",
       "1 -0.046777  0.063672  0.102014 -0.096680  0.005133 -0.038660  \n",
       "2  0.065600  0.016942 -0.007010 -0.075910  0.066668 -0.069632  \n",
       "3 -0.064236  0.040677  0.076152  0.029161 -0.007053 -0.011149  \n",
       "4 -0.139221 -0.001038 -0.003777 -0.038452  0.109802 -0.061951  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_vectors= pd.DataFrame()\n",
    "for doc in data['Clean_Tweets']:  \n",
    "    temp= pd.DataFrame()        \n",
    "    words= doc.split(' ')       \n",
    "    for word in words:           \n",
    "        try:\n",
    "            words2vec= embeddings[word]               \n",
    "            temp= temp.append(pd.Series(words2vec),ignore_index=True)  \n",
    "            \n",
    "        except:  \n",
    "            pass\n",
    "    doc_vector= temp.mean() \n",
    "    docs_vectors= docs_vectors.append(doc_vector,ignore_index= True)  \n",
    "docs_vectors.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      66\n",
       "1      66\n",
       "2      66\n",
       "3      66\n",
       "4      66\n",
       "       ..\n",
       "295    66\n",
       "296    66\n",
       "297    66\n",
       "298    66\n",
       "299    66\n",
       "Length: 300, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_vectors.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectors= docs_vectors.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "295    0\n",
       "296    0\n",
       "297    0\n",
       "298    0\n",
       "299    0\n",
       "Length: 300, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_vectors.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= docs_vectors\n",
    "y= data['flagged_sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arpitha Ananth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Arpitha Ananth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "LogReg= LogisticRegression()\n",
    "LogReg= LogReg.fit(X_train,y_train)\n",
    "\n",
    "y_pred= LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.7750455373406193\n",
      "Confusion Matrix: \n",
      "[[2638  131   45]\n",
      " [ 477  336   71]\n",
      " [ 183   81  430]]\n"
     ]
    }
   ],
   "source": [
    "LRA= metrics.accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy Score: \", LRA)\n",
    "cm= confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix: \",cm,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7378483442804221"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "LogReg= multiclass_roc_auc_score(y_test,y_pred)\n",
    "LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn= KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred= knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.7363387978142076\n",
      "Confusion Matrix: \n",
      "[[2669   91   54]\n",
      " [ 617  217   50]\n",
      " [ 295   51  348]]\n"
     ]
    }
   ],
   "source": [
    "KNNA= metrics.accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy Score: \",KNNA)\n",
    "cm= confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix: \",cm,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6748064963464971"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "KNN= multiclass_roc_auc_score(y_test,y_pred)\n",
    "KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc= DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred= dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6318306010928961\n",
      "Confusion Matrix: \n",
      "[[2111  436  267]\n",
      " [ 403  337  144]\n",
      " [ 236  131  327]]\n"
     ]
    }
   ],
   "source": [
    "DTA= metrics.accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy Score: \",DTA)\n",
    "cm= confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix: \",cm,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6541443794636213"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "DT= multiclass_roc_auc_score(y_test,y_pred)\n",
    "DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred= rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.7509107468123861\n",
      "Confusion Matrix: \n",
      "[[2696   98   20]\n",
      " [ 557  281   46]\n",
      " [ 320   53  321]]\n"
     ]
    }
   ],
   "source": [
    "RFA= metrics.accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy Score: \",RFA)\n",
    "cm= confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix: \",cm,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.686969564452571"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "RF= multiclass_roc_auc_score(y_test,y_pred)\n",
    "RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada= AdaBoostClassifier(n_estimators=100,random_state=0)\n",
    "ada.fit(X_train,y_train)\n",
    "y_pred= ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.7358834244080146\n",
      "Confusion Matrix: \n",
      "[[2463  233  118]\n",
      " [ 450  345   89]\n",
      " [ 180   90  424]]\n"
     ]
    }
   ],
   "source": [
    "ADAA= metrics.accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy Score: \",ADAA)\n",
    "cm= confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix: \",cm,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7215330037904361"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "AD= multiclass_roc_auc_score(y_test,y_pred)\n",
    "AD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient= GradientBoostingClassifier(n_estimators=200,random_state=0,max_depth=2)\n",
    "gradient.fit(X_train,y_train)\n",
    "y_pred= gradient.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.770264116575592\n",
      "Confusion Matrix: \n",
      "[[2604  149   61]\n",
      " [ 452  370   62]\n",
      " [ 207   78  409]]\n"
     ]
    }
   ],
   "source": [
    "GBA= metrics.accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy Score: \",GBA)\n",
    "cm= confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix: \",cm,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7362791084994744"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "GB= multiclass_roc_auc_score(y_test,y_pred)\n",
    "GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "Xg= GradientBoostingClassifier(n_estimators=200,random_state=0,max_depth=2)\n",
    "Xg.fit(X_train,y_train)\n",
    "y_pred= Xg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.770264116575592\n",
      "Confusion Matrix: \n",
      "[[2604  149   61]\n",
      " [ 452  370   62]\n",
      " [ 207   78  409]]\n"
     ]
    }
   ],
   "source": [
    "XGA= metrics.accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy Score: \",XGA)\n",
    "cm= confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix: \",cm,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7362791084994744"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "XG= multiclass_roc_auc_score(y_test,y_pred)\n",
    "XG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Of ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.775046</td>\n",
       "      <td>0.737848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.736339</td>\n",
       "      <td>0.674806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.631831</td>\n",
       "      <td>0.654144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.750911</td>\n",
       "      <td>0.686970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.735883</td>\n",
       "      <td>0.721533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.770264</td>\n",
       "      <td>0.736279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XG Boost</th>\n",
       "      <td>0.770264</td>\n",
       "      <td>0.736279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy   AUC-ROC\n",
       "Logistic Regression  0.775046  0.737848\n",
       "KNN                  0.736339  0.674806\n",
       "Decision Tree        0.631831  0.654144\n",
       "Random Forest        0.750911  0.686970\n",
       "Ada Boost            0.735883  0.721533\n",
       "Gradient Boost       0.770264  0.736279\n",
       "XG Boost             0.770264  0.736279"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Algorithms= ['Logistic Regression','KNN','Decision Tree','Random Forest','Ada Boost','Gradient Boost','XG Boost']\n",
    "Accuracy= [LRA,KNNA,DTA,RFA,ADAA,GBA,XGA]\n",
    "AUC_ROC= [LogReg,KNN,DT,RF,AD,GB,XG]\n",
    "comp= pd.DataFrame([Accuracy,AUC_ROC]).T\n",
    "comp.set_index([Algorithms],inplace=True)\n",
    "comp.columns=['Accuracy','AUC-ROC']\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cd99f9f898>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comp.plot(kind='bar',figsize=(15,5),rot=0,title='Model Comparison for Word Embedding',colors=['teal','darkseagreen'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
